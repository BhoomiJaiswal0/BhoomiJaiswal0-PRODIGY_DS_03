# -*- coding: utf-8 -*-
"""Untitled4.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1cVyl9Uxl_Zj2mCUALRfEhw4LON4FUOj9

# ğŸ“Š Decision Tree Classifier on Bank Marketing Dataset

## ğŸ” Objective
Build a Decision Tree Classifier to predict whether a customer will purchase a term deposit based on demographic and behavioral data.

## ğŸ“‚ Dataset
- **Name**: Bank Marketing Dataset
- **Source**: UCI Machine Learning Repository
- **Target**: `y` â†’ whether the client subscribed to a term deposit (yes/no)

---

## ğŸ“¥ Step 1: Load and Explore Data
"""

import pandas as pd
data = pd.read_csv('bank-full.csv', sep=';')
data.head()

"""## ğŸ§¹ Step 2: Preprocessing

- Convert categorical variables using One-Hot Encoding
- Convert target variable 'y' using Label Encoding

"""

from sklearn.preprocessing import LabelEncoder

# Encoding the target variable 'y'
le = LabelEncoder()
data['y'] = le.fit_transform(data['y'])  # yes=1, no=0

# One-hot encode all categorical columns (drop_first to avoid dummy variable trap)
data_encoded = pd.get_dummies(data, drop_first=True)

# Let's check the updated shape and sample
print("New shape:", data_encoded.shape)
data_encoded.head()

"""## ğŸ”€ Step 3: Train-Test Split

"""

from sklearn.model_selection import train_test_split

# Separating features (X) and target (y)
X = data_encoded.drop('y', axis=1)
y = data_encoded['y']

# Spliting into training (80%) and testing (20%)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Checking shapes
print("Training shape:", X_train.shape)
print("Testing shape:", X_test.shape)

"""## ğŸŒ³ Step 4: Train Decision Tree Model

"""

from sklearn.tree import DecisionTreeClassifier

# Initializing the model
model = DecisionTreeClassifier(random_state=42)

# Training the model
model.fit(X_train, y_train)

"""## ğŸ“ˆ Step 5: Evaluate the Model

"""

from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

# Making predictions on the test set
y_pred = model.predict(X_test)

# Accuracy
print("Accuracy:", accuracy_score(y_test, y_pred))

# Classification report
print("\nClassification Report:\n", classification_report(y_test, y_pred))

# Confusion matrix
print("\nConfusion Matrix:\n", confusion_matrix(y_test, y_pred))

"""## ğŸŒ¿ Step 6: Visualize the Decision Tree"""

from sklearn.tree import plot_tree
import matplotlib.pyplot as plt

plt.figure(figsize=(20,10))
plot_tree(model, feature_names=X.columns, class_names=['No', 'Yes'], filled=True, max_depth=3)
plt.title("Decision Tree (Depth: 3 for simplicity)")
plt.show()

"""## â­ Step 7: Feature Importance"""

import numpy as np

importances = model.feature_importances_
indices = np.argsort(importances)[-10:]  # Top 10 features

plt.figure(figsize=(10,6))
plt.title("Top 10 Important Features")
plt.barh(range(len(indices)), importances[indices], align='center')
plt.yticks(range(len(indices)), [X.columns[i] for i in indices])
plt.xlabel("Relative Importance")
plt.show()

"""## âœ… Conclusion

- Accuracy: ~87%
- The model is good at identifying non-buyers.
- Could improve performance on buyers using class balancing or ensemble models.
- Decision Trees are interpretable and helpful in customer targeting scenarios.

"""